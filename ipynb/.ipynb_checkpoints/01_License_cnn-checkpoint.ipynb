{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像列表已生成\n"
     ]
    }
   ],
   "source": [
    "data_path = 'D:/python note/License/cnn_char_train'\n",
    "character_folders = os.listdir(data_path)\n",
    "label = 0\n",
    "LABEL_temp = {}\n",
    "if(os.path.exists('./train_data.list')):\n",
    "    os.remove('./train_data.list')\n",
    "if(os.path.exists('./test_data.list')):\n",
    "    os.remove('./test_data.list')\n",
    "for character_folder in character_folders:\n",
    "    with open('./train_data.list', 'a') as f_train:\n",
    "        with open('./test_data.list', 'a') as f_test:\n",
    "            if character_folder == '.DS_Store' or character_folder == '.ipynb_checkpoints' or character_folder == 'data23617':\n",
    "                continue\n",
    "            #print(character_folder + \" \" + str(label))\n",
    "            LABEL_temp[str(label)] = character_folder     #存储一下标签的对应关系\n",
    "            character_imgs = os.listdir(os.path.join(data_path, character_folder))\n",
    "            for i in range(len(character_imgs)):\n",
    "                if i%10 == 0:\n",
    "                    f_test.write(os.path.join(os.path.join(data_path, character_folder), character_imgs[i]) + \"\\t\" + str(label) + '\\n')\n",
    "                else:\n",
    "                    f_train.write(os.path.join(os.path.join(data_path, character_folder), character_imgs[i]) + \"\\t\" + str(label) + '\\n')\n",
    "    label = label + 1\n",
    "print('图像列表已生成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_paths = []\n",
    "all_image_labels = []\n",
    "test_image_paths = []\n",
    "test_image_labels = []\n",
    "with open('./train_data.list', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        img, label = line.split('\\t')\n",
    "        all_image_paths.append(img)\n",
    "        all_image_labels.append(int(label))\n",
    "with open('./test_data.list', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        img, label = line.split('\\t')\n",
    "        test_image_paths.append(img)\n",
    "        test_image_labels.append(int(label))\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image,dtype=tf.float32)\n",
    "    image = tf.image.resize(image, (80, 20)\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path,label):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image), label\n",
    "\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))\n",
    "train_data = ds.map(load_and_preprocess_image).batch(64)\n",
    "db = tf.data.Dataset.from_tensor_slices((test_image_paths, test_image_labels))\n",
    "test_data = db.map(load_and_preprocess_image).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16148"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_image_paths)+len(test_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            multiple                  896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch multiple                  128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           multiple                  18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           multiple                  36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  3277312   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  65664     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  8385      \n",
      "=================================================================\n",
      "Total params: 3,408,321\n",
      "Trainable params: 3,408,001\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Train for 227 steps, validate for 26 steps\n",
      "Epoch 1/60\n",
      "227/227 [==============================] - 61s 270ms/step - loss: 2.9331 - accuracy: 0.3899 - val_loss: 3.9951 - val_accuracy: 0.0687\n",
      "Epoch 2/60\n",
      "227/227 [==============================] - 14s 60ms/step - loss: 1.9781 - accuracy: 0.5620 - val_loss: 2.7686 - val_accuracy: 0.5903\n",
      "Epoch 3/60\n",
      "227/227 [==============================] - 14s 60ms/step - loss: 1.4903 - accuracy: 0.6776 - val_loss: 1.8888 - val_accuracy: 0.6614\n",
      "Epoch 4/60\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 1.2063 - accuracy: 0.7368 - val_loss: 1.4974 - val_accuracy: 0.6821\n",
      "Epoch 5/60\n",
      "227/227 [==============================] - 13s 59ms/step - loss: 1.0237 - accuracy: 0.7736 - val_loss: 1.2580 - val_accuracy: 0.7398\n",
      "Epoch 6/60\n",
      "227/227 [==============================] - 14s 61ms/step - loss: 0.8731 - accuracy: 0.8084 - val_loss: 1.0436 - val_accuracy: 0.7927\n",
      "Epoch 7/60\n",
      "227/227 [==============================] - 14s 61ms/step - loss: 0.7774 - accuracy: 0.8265 - val_loss: 0.8737 - val_accuracy: 0.8231\n",
      "Epoch 8/60\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.6951 - accuracy: 0.8451 - val_loss: 0.7748 - val_accuracy: 0.8395\n",
      "Epoch 9/60\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.6327 - accuracy: 0.8609 - val_loss: 0.7000 - val_accuracy: 0.8584\n",
      "Epoch 10/60\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 0.5915 - accuracy: 0.8675 - val_loss: 0.6286 - val_accuracy: 0.8650\n",
      "Epoch 11/60\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.5387 - accuracy: 0.8782 - val_loss: 0.5850 - val_accuracy: 0.8699\n",
      "Epoch 12/60\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.4951 - accuracy: 0.8893 - val_loss: 0.5276 - val_accuracy: 0.8869\n",
      "Epoch 13/60\n",
      "227/227 [==============================] - 14s 61ms/step - loss: 0.4559 - accuracy: 0.8998 - val_loss: 0.5005 - val_accuracy: 0.8906\n",
      "Epoch 14/60\n",
      "227/227 [==============================] - 14s 60ms/step - loss: 0.4343 - accuracy: 0.9024 - val_loss: 0.4935 - val_accuracy: 0.8912\n",
      "Epoch 15/60\n",
      "227/227 [==============================] - 14s 64ms/step - loss: 0.4025 - accuracy: 0.9098 - val_loss: 0.4670 - val_accuracy: 0.8948\n",
      "Epoch 16/60\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 0.3782 - accuracy: 0.9152 - val_loss: 0.4452 - val_accuracy: 0.8948\n",
      "Epoch 17/60\n",
      "227/227 [==============================] - 13s 59ms/step - loss: 0.3531 - accuracy: 0.9207 - val_loss: 0.4275 - val_accuracy: 0.8973\n",
      "Epoch 18/60\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.3362 - accuracy: 0.9244 - val_loss: 0.3956 - val_accuracy: 0.9040\n",
      "Epoch 19/60\n",
      "227/227 [==============================] - 14s 64ms/step - loss: 0.3120 - accuracy: 0.9313 - val_loss: 0.3959 - val_accuracy: 0.9040\n",
      "Epoch 20/60\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.2970 - accuracy: 0.9330 - val_loss: 0.3668 - val_accuracy: 0.9143\n",
      "Epoch 21/60\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 0.2846 - accuracy: 0.9368 - val_loss: 0.3520 - val_accuracy: 0.9137\n",
      "Epoch 22/60\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 0.2666 - accuracy: 0.9408 - val_loss: 0.3300 - val_accuracy: 0.9191\n",
      "Epoch 23/60\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 0.2527 - accuracy: 0.9431 - val_loss: 0.3238 - val_accuracy: 0.9216\n",
      "Epoch 24/60\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 0.2430 - accuracy: 0.9459 - val_loss: 0.2964 - val_accuracy: 0.9234\n",
      "Epoch 25/60\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 0.2320 - accuracy: 0.9476 - val_loss: 0.2908 - val_accuracy: 0.9246\n",
      "Epoch 26/60\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 0.2261 - accuracy: 0.9488 - val_loss: 0.2762 - val_accuracy: 0.9264\n",
      "Epoch 27/60\n",
      "227/227 [==============================] - 15s 65ms/step - loss: 0.2148 - accuracy: 0.9532 - val_loss: 0.2479 - val_accuracy: 0.9392\n",
      "Epoch 28/60\n",
      "227/227 [==============================] - 14s 60ms/step - loss: 0.2064 - accuracy: 0.9541 - val_loss: 0.2299 - val_accuracy: 0.9422\n",
      "Epoch 29/60\n",
      "227/227 [==============================] - 15s 67ms/step - loss: 0.1962 - accuracy: 0.9558 - val_loss: 0.2335 - val_accuracy: 0.9441\n",
      "Epoch 30/60\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 0.1884 - accuracy: 0.9591 - val_loss: 0.2184 - val_accuracy: 0.9471\n",
      "Epoch 31/60\n",
      "227/227 [==============================] - 22s 97ms/step - loss: 0.1808 - accuracy: 0.9595 - val_loss: 0.2204 - val_accuracy: 0.9495\n",
      "Epoch 32/60\n",
      "227/227 [==============================] - 17s 73ms/step - loss: 0.1699 - accuracy: 0.9621 - val_loss: 0.2068 - val_accuracy: 0.9520\n",
      "Epoch 33/60\n",
      "227/227 [==============================] - 14s 64ms/step - loss: 0.1690 - accuracy: 0.9605 - val_loss: 0.2027 - val_accuracy: 0.9514\n",
      "Epoch 34/60\n",
      "227/227 [==============================] - 15s 65ms/step - loss: 0.1649 - accuracy: 0.9628 - val_loss: 0.1984 - val_accuracy: 0.9550\n",
      "Epoch 35/60\n",
      "227/227 [==============================] - 15s 67ms/step - loss: 0.1620 - accuracy: 0.9629 - val_loss: 0.1916 - val_accuracy: 0.9550\n",
      "Epoch 36/60\n",
      "227/227 [==============================] - 14s 60ms/step - loss: 0.1567 - accuracy: 0.9643 - val_loss: 0.1935 - val_accuracy: 0.9538\n",
      "Epoch 37/60\n",
      "227/227 [==============================] - 15s 65ms/step - loss: 0.1503 - accuracy: 0.9658 - val_loss: 0.1848 - val_accuracy: 0.9556\n",
      "Epoch 38/60\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.1447 - accuracy: 0.9664 - val_loss: 0.1868 - val_accuracy: 0.9538\n",
      "Epoch 39/60\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 0.1422 - accuracy: 0.9664 - val_loss: 0.1811 - val_accuracy: 0.9568\n",
      "Epoch 40/60\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 0.1393 - accuracy: 0.9686 - val_loss: 0.1742 - val_accuracy: 0.9581\n",
      "Epoch 41/60\n",
      "227/227 [==============================] - 14s 61ms/step - loss: 0.1369 - accuracy: 0.9678 - val_loss: 0.1748 - val_accuracy: 0.9568\n",
      "Epoch 42/60\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.1314 - accuracy: 0.9686 - val_loss: 0.1773 - val_accuracy: 0.9562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/60\n",
      "227/227 [==============================] - 14s 61ms/step - loss: 0.1291 - accuracy: 0.9696 - val_loss: 0.1694 - val_accuracy: 0.9581\n",
      "Epoch 44/60\n",
      "227/227 [==============================] - 14s 61ms/step - loss: 0.1239 - accuracy: 0.9727 - val_loss: 0.1640 - val_accuracy: 0.9587\n",
      "Epoch 45/60\n",
      "227/227 [==============================] - 14s 60ms/step - loss: 0.1196 - accuracy: 0.9713 - val_loss: 0.1612 - val_accuracy: 0.9599\n",
      "Epoch 46/60\n",
      "227/227 [==============================] - 14s 61ms/step - loss: 0.1166 - accuracy: 0.9718 - val_loss: 0.1620 - val_accuracy: 0.9599\n",
      "Epoch 47/60\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.1135 - accuracy: 0.9738 - val_loss: 0.1628 - val_accuracy: 0.9587\n",
      "Epoch 48/60\n",
      "227/227 [==============================] - 14s 61ms/step - loss: 0.1122 - accuracy: 0.9732 - val_loss: 0.1575 - val_accuracy: 0.9641\n",
      "Epoch 49/60\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.1114 - accuracy: 0.9739 - val_loss: 0.1496 - val_accuracy: 0.9641\n",
      "Epoch 50/60\n",
      "227/227 [==============================] - 15s 67ms/step - loss: 0.1064 - accuracy: 0.9746 - val_loss: 0.1482 - val_accuracy: 0.9672\n",
      "Epoch 51/60\n",
      "227/227 [==============================] - 15s 68ms/step - loss: 0.1042 - accuracy: 0.9765 - val_loss: 0.1443 - val_accuracy: 0.9684\n",
      "Epoch 52/60\n",
      "227/227 [==============================] - 15s 68ms/step - loss: 0.0999 - accuracy: 0.9757 - val_loss: 0.1395 - val_accuracy: 0.9684\n",
      "Epoch 53/60\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 0.1010 - accuracy: 0.9766 - val_loss: 0.1432 - val_accuracy: 0.9690\n",
      "Epoch 54/60\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 0.0968 - accuracy: 0.9768 - val_loss: 0.1365 - val_accuracy: 0.9678\n",
      "Epoch 55/60\n",
      "227/227 [==============================] - 15s 64ms/step - loss: 0.0948 - accuracy: 0.9793 - val_loss: 0.1385 - val_accuracy: 0.9678\n",
      "Epoch 56/60\n",
      "227/227 [==============================] - 15s 65ms/step - loss: 0.0889 - accuracy: 0.9788 - val_loss: 0.1351 - val_accuracy: 0.9690\n",
      "Epoch 57/60\n",
      "227/227 [==============================] - 15s 64ms/step - loss: 0.0903 - accuracy: 0.9794 - val_loss: 0.1306 - val_accuracy: 0.9690\n",
      "Epoch 58/60\n",
      "227/227 [==============================] - 15s 66ms/step - loss: 0.0883 - accuracy: 0.9802 - val_loss: 0.1330 - val_accuracy: 0.9690\n",
      "Epoch 59/60\n",
      "227/227 [==============================] - 15s 67ms/step - loss: 0.0897 - accuracy: 0.9806 - val_loss: 0.1340 - val_accuracy: 0.9684\n",
      "Epoch 60/60\n",
      "227/227 [==============================] - 16s 70ms/step - loss: 0.0842 - accuracy: 0.9802 - val_loss: 0.1304 - val_accuracy: 0.9684\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.1304 - accuracy: 0.9684\n",
      "INFO:tensorflow:Assets written to: D:/python note/License/model/assets\n"
     ]
    }
   ],
   "source": [
    "def train_model(train_data,test_data):\n",
    "    #构建模型\n",
    "    network = keras.Sequential([\n",
    "        keras.layers.Conv2D(32, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "        keras.layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "        keras.layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(65)])\n",
    "    network.build(input_shape=(None, 80, 20, 3))\n",
    "    network.summary()\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=10, mode='auto')\n",
    "    network.compile(optimizer=optimizers.SGD(lr=0.001),\n",
    "                    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=['accuracy'])\n",
    "    network.fit(train_data, epochs=60, validation_data=test_data, callbacks=[reduce_lr])\n",
    "    network.evaluate(test_data)\n",
    "    tf.saved_model.save(network, 'D:/python note/License/model/')\n",
    "    \n",
    "train_model(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
